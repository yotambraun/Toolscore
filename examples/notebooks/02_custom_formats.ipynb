{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with Custom Trace Formats\n",
    "\n",
    "This notebook shows how to use Toolscore with custom trace formats beyond OpenAI and Anthropic.\n",
    "\n",
    "## What You'll Learn\n",
    "\n",
    "1. Understanding the custom format structure\n",
    "2. Creating custom gold standards\n",
    "3. Evaluating custom traces\n",
    "4. Best practices for custom formats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../..')  # For development\n",
    "\n",
    "from toolscore import evaluate_trace\n",
    "import json\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Custom Format Structure\n",
    "\n",
    "The custom format is flexible and can handle various structures:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 1: Dictionary with 'calls' array\n",
    "custom_format_1 = {\n",
    "    \"calls\": [\n",
    "        {\n",
    "            \"tool\": \"search_web\",\n",
    "            \"args\": {\"query\": \"Python tutorials\", \"num_results\": 10},\n",
    "            \"result\": \"Found 10 results\"\n",
    "        },\n",
    "        {\n",
    "            \"tool\": \"summarize\",\n",
    "            \"args\": {\"text\": \"...\"},\n",
    "            \"result\": \"Summary created\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "print(\"Custom Format 1:\")\n",
    "print(json.dumps(custom_format_1, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 2: Direct array of calls\n",
    "custom_format_2 = [\n",
    "    {\n",
    "        \"name\": \"read_file\",  # 'name' or 'tool' both work\n",
    "        \"arguments\": {\"path\": \"data.txt\"},  # 'arguments' or 'args' both work\n",
    "    },\n",
    "    {\n",
    "        \"tool\": \"write_file\",\n",
    "        \"args\": {\"path\": \"output.txt\", \"content\": \"processed data\"},\n",
    "    }\n",
    "]\n",
    "\n",
    "print(\"Custom Format 2:\")\n",
    "print(json.dumps(custom_format_2, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create a Custom Trace\n",
    "\n",
    "Let's create a complete custom trace for evaluation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom trace for a file processing workflow\n",
    "custom_trace = {\n",
    "    \"calls\": [\n",
    "        {\n",
    "            \"tool\": \"read_file\",\n",
    "            \"args\": {\"filename\": \"input.txt\"},\n",
    "            \"result\": \"File content loaded\",\n",
    "            \"timestamp\": 1234567890.0,\n",
    "            \"duration\": 0.05\n",
    "        },\n",
    "        {\n",
    "            \"tool\": \"process_text\",\n",
    "            \"args\": {\"text\": \"...\", \"operation\": \"uppercase\"},\n",
    "            \"result\": \"Processed successfully\",\n",
    "            \"duration\": 0.12\n",
    "        },\n",
    "        {\n",
    "            \"tool\": \"write_file\",\n",
    "            \"args\": {\"filename\": \"output.txt\", \"content\": \"...\"},\n",
    "            \"result\": \"File written\",\n",
    "            \"duration\": 0.03\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Save to file\n",
    "with open(\"custom_trace.json\", \"w\") as f:\n",
    "    json.dump(custom_trace, f, indent=2)\n",
    "\n",
    "print(\"✅ Custom trace created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Create Gold Standard\n",
    "\n",
    "Define the expected behavior:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_standard = [\n",
    "    {\n",
    "        \"tool\": \"read_file\",\n",
    "        \"args\": {\"filename\": \"input.txt\"},\n",
    "        \"description\": \"Read input file\",\n",
    "        \"side_effects\": {\n",
    "            \"file_exists\": \"input.txt\"\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"tool\": \"process_text\",\n",
    "        \"args\": {\"operation\": \"uppercase\"},\n",
    "        \"description\": \"Process text to uppercase\"\n",
    "    },\n",
    "    {\n",
    "        \"tool\": \"write_file\",\n",
    "        \"args\": {\"filename\": \"output.txt\"},\n",
    "        \"description\": \"Write processed output\",\n",
    "        \"side_effects\": {\n",
    "            \"file_exists\": \"output.txt\"\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "# Save gold standard\n",
    "with open(\"custom_gold.json\", \"w\") as f:\n",
    "    json.dump(gold_standard, f, indent=2)\n",
    "\n",
    "print(\"✅ Gold standard created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Run Evaluation\n",
    "\n",
    "Evaluate the custom trace:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = evaluate_trace(\n",
    "    gold_file=\"custom_gold.json\",\n",
    "    trace_file=\"custom_trace.json\",\n",
    "    format=\"custom\"  # Explicitly specify custom format\n",
    ")\n",
    "\n",
    "print(\"=== Evaluation Results ===\")\n",
    "print(f\"Invocation Accuracy: {result.metrics['invocation_accuracy']:.1%}\")\n",
    "print(f\"Selection Accuracy:  {result.metrics['selection_accuracy']:.1%}\")\n",
    "print(f\"Sequence Accuracy:   {result.metrics['sequence_metrics']['sequence_accuracy']:.1%}\")\n",
    "print(f\"Argument F1:         {result.metrics['argument_metrics']['f1']:.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Performance Metrics\n",
    "\n",
    "Custom traces can include performance data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if latency metrics are available\n",
    "if 'latency_metrics' in result.metrics:\n",
    "    lat = result.metrics['latency_metrics']\n",
    "    print(\"Performance Metrics:\")\n",
    "    print(f\"Total Duration:   {lat['total_duration']:.3f}s\")\n",
    "    print(f\"Average Duration: {lat['average_duration']:.3f}s\")\n",
    "    print(f\"Max Duration:     {lat['max_duration']:.3f}s\")\n",
    "    print(f\"Min Duration:     {lat['min_duration']:.3f}s\")\n",
    "else:\n",
    "    print(\"No latency data in trace\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Auto-Detection\n",
    "\n",
    "Toolscore can auto-detect custom formats:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use auto-detection\n",
    "result_auto = evaluate_trace(\n",
    "    gold_file=\"custom_gold.json\",\n",
    "    trace_file=\"custom_trace.json\",\n",
    "    format=\"auto\"  # Will detect it's a custom format\n",
    ")\n",
    "\n",
    "print(f\"Auto-detected format evaluation:\")\n",
    "print(f\"Selection Accuracy: {result_auto.metrics['selection_accuracy']:.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Best Practices\n",
    "\n",
    "### Tips for Custom Formats:\n",
    "\n",
    "1. **Use consistent field names**: Stick to either `tool`/`args` or `name`/`arguments`\n",
    "2. **Include metadata**: Add timestamps, durations, costs when available\n",
    "3. **Document your format**: Keep a schema for your custom format\n",
    "4. **Test incrementally**: Start with simple cases before complex workflows\n",
    "5. **Use side-effects**: Validate important outcomes (files created, API calls, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Real-World Example\n",
    "\n",
    "Here's a more complex custom trace:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complex_trace = {\n",
    "    \"metadata\": {\n",
    "        \"agent_id\": \"agent-123\",\n",
    "        \"session_id\": \"session-456\",\n",
    "        \"timestamp\": \"2025-10-13T12:00:00Z\"\n",
    "    },\n",
    "    \"calls\": [\n",
    "        {\n",
    "            \"tool\": \"api_call\",\n",
    "            \"args\": {\n",
    "                \"url\": \"https://api.example.com/users\",\n",
    "                \"method\": \"GET\"\n",
    "            },\n",
    "            \"result\": {\"status\": 200, \"users\": [...]},\n",
    "            \"duration\": 0.5,\n",
    "            \"cost\": 0.0001\n",
    "        },\n",
    "        {\n",
    "            \"tool\": \"filter_data\",\n",
    "            \"args\": {\"condition\": \"active_users\"},\n",
    "            \"result\": {\"count\": 42},\n",
    "            \"duration\": 0.02\n",
    "        },\n",
    "        {\n",
    "            \"tool\": \"generate_report\",\n",
    "            \"args\": {\"format\": \"pdf\", \"template\": \"summary\"},\n",
    "            \"result\": {\"file\": \"report.pdf\", \"pages\": 5},\n",
    "            \"duration\": 1.2\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "print(\"Complex custom trace structure:\")\n",
    "print(json.dumps(complex_trace, indent=2)[:500], \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this notebook, you learned:\n",
    "\n",
    "✅ How to structure custom trace formats\n",
    "\n",
    "✅ How to create gold standards for custom workflows\n",
    "\n",
    "✅ How to evaluate custom traces\n",
    "\n",
    "✅ How to include performance metrics\n",
    "\n",
    "✅ Best practices for custom format design\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "- Check out `03_advanced_metrics.ipynb` for deep dives into specific metrics\n",
    "- Adapt this approach to your own agent framework\n",
    "- Read the [custom adapter documentation](https://toolscore.readthedocs.io/en/latest/api/adapters.html)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
